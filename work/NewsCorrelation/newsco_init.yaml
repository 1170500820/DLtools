#预训练模型
model_type: 'xlm-roberta-base'
pretrained_model_dir: './data/model/pretrained_model/xlm-roberta-base'


# 路径
crawl_data_dir: './Crawl/final_nlp'
train_file: './data/train_file.csv'     # 训练文件由split生成，文件的路径应该保持一致 TODO
valid_file: './data/valid_file.csv'       # TODO: 加载训练数据和valid数据集和test数据集
show_data_path: './data/show_data'    # 展示一下预测错的文本。
word_dic_path: './data/word_dic.pkl'
word_embbed_path: './data/word_embed.npy'


# 数据预处理参数

batch_size: 8
text_use_line_num: 3         #
text_use_all: True          # 设置为true的时候使用了所有的正文，设置使用行数就无效了
title_len: 30
text_len: 100   #  100
summary_len: 50
meta_descrip_len: 10

total_len: 280  # 2 * (title_len + text_len + meta_descrip_len) + 22

start_seg: 0        #用0进行开始
padding_seg: 1      #用1进行padding
seq_end_seg: 2      # 用2表示结束符号

# 实体相关
entity_len: 10
entity_neighbor_len: 20


# 模型参数

conv_output_channels: 128
layer_size: 200


# 训练参数
epoch_num: 80
seed: 27  # 7
gradient_accumulation_steps: 1
#   优化器
learning_rate: 0.0001
pretrained_model_learning_rate: 0.00001


# 保存模型设置
save_model: False
save_model_epochs: 10      # 每这么多个epoch保存一次模型
save_model_path: 'checkpoints/cnn/checkpoint'


# 预处理划分训练数据集、测试数据集 TODO
split_data: False     #
split_source_data: './Crawl/semeval-2022_task8_train-data_batch.csv'
split_train_data_path: './data/train_file.csv'  # 修改以后需要修改train_file
split_valid_data_path: './data/valid_file.csv'  # 修改以后需要修改valid_file
split_ratio: 0.1    # 验证数据集所占比例
start_ratio: 0.1    # 测试集开始位置（设置为0.9时，测试集0.9-1之间为验证集）
shuffle_seed: 5     # 在不修改seed的情况下每次shuffle的结果是一样的，可以十折交叉验证

use_all: False  # 设置为False的时候将只针对use_lang_pairs中的数据划分，划分为训练集和测试集（其他种类的数据不包含在训练文件和测试文件中，丢弃）
use_lang_pairs: ['en-en','de-de','de-en','ar-ar','es-es','fr-fr','pl-pl','tr-tr']
# use_lang_pairs: ['en-en']


glove_emb_path: './data/glove.6B.300d.txt'
pre_embed_size: 300
word_dic_savepath: './data/word_dic.pkl'

word_embbeding_savepath: './data/word_embed.npy'



